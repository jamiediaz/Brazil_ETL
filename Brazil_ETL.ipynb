{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brazil_ETL\n",
    "\n",
    "Here we are extracting monthly burn data for the area of the State of Amazonas, Brazil.<br>\n",
    "<br>\n",
    "We will be looking at a five year span from 2012 to 2016.  The goal is to try and see <br>\n",
    "if there is an increase in the amount of forest fires in the region and if the demand <br>\n",
    "for soybean and corn is directly linked to it. \n",
    "\n",
    "### Data files\n",
    "\n",
    "We will be using soybean and corn data gathered from Kaggle.com and burn data gathered from <br>\n",
    "the Global Fire Emissions Database (GFED).  Data from GFED are all stored in HDF5 files and <br>\n",
    "requires some drilling down to get to the tables we need -- the monthly burned areas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tables\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://sqladmin:password@localhost:5432/brazil_etl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dthe data_get function \n",
    "\n",
    "This will grab the HDF5 file and go down to the burned_area data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_get(HDF5_file):\n",
    "    hdf = h5py.File(HDF5_file, \"r\")\n",
    "    return hdf['burned_area']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the data_get function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_2016 = data_get(\"Resources\\GFED4_1s_2016.hdf5\")\n",
    "ba_2015 = data_get(\"Resources\\GFED4_1s_2015.hdf5\")\n",
    "ba_2014 = data_get(\"Resources\\GFED4_1s_2014.hdf5\")\n",
    "ba_2013 = data_get(\"Resources\\GFED4_1s_2013.hdf5\")\n",
    "ba_2012 = data_get(\"Resources\\GFED4_1s_2012.hdf5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to drill into the HDF5 file\n",
    "\n",
    "The table we need resides in burned fraction under each month of the year. <br>\n",
    "We will extract this data and put it to a dataframe.<br>\n",
    "We then filter the data frame from column 426 to 494  and from row 352 to 397.<br>\n",
    "The table corresponds to the lat, long coordinates for the rectangular area that <br>\n",
    "is roughly the area of the State of Amazonas, Brazil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drill_down(ba_YYYY,mnth):\n",
    "    ba_mnth = ba_YYYY[mnth]\n",
    "    bf_mnth = ba_mnth['burned_fraction']\n",
    "    bf_mnth_df = pd.DataFrame(bf_mnth)\n",
    "    return bf_mnth_df.iloc[352:397,426:494]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calling the drill_down function \n",
    "We call the function for each month starting with January 2016. <br>\n",
    "We then feed the dataframes to the brazil_etl database in postgresql<br>\n",
    "Where we will be doing the calculations to find the percentage of area burned per month, year, and half decade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'bf_2016_01' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-37b93f522705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbf_2016_01_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrill_down\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mba_2016\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbf_2016_01_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bf_2016_01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbf_2016_02_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrill_down\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mba_2016\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'02'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbf_2016_02_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bf_2016_02'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2529\u001b[0m         sql.to_sql(self, name, con, schema=schema, if_exists=if_exists,\n\u001b[0;32m   2530\u001b[0m                    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m                    dtype=dtype, method=method)\n\u001b[0m\u001b[0;32m   2532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    458\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[0;32m    459\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m                       chunksize=chunksize, dtype=dtype, method=method)\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                          \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                          schema=schema, dtype=dtype)\n\u001b[1;32m-> 1173\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fail'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 575\u001b[1;33m                     \"Table '{name}' already exists.\".format(name=self.name))\n\u001b[0m\u001b[0;32m    576\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'bf_2016_01' already exists."
     ]
    }
   ],
   "source": [
    "bf_2016_01_df = drill_down(ba_2016,'01')\n",
    "bf_2016_01_df.to_sql('bf_2016_01', engine)\n",
    "\n",
    "bf_2016_02_df = drill_down(ba_2016,'02')\n",
    "bf_2016_02_df.to_sql('bf_2016_02', engine)\n",
    "\n",
    "bf_2016_03_df = drill_down(ba_2016,'03')\n",
    "bf_2016_03_df.to_sql('bf_2016_03', engine)\n",
    "\n",
    "bf_2016_04_df = drill_down(ba_2016,'04')\n",
    "bf_2016_04_df.to_sql('bf_2016_04', engine)\n",
    "\n",
    "bf_2016_05_df = drill_down(ba_2016,'05')\n",
    "bf_2016_05_df.to_sql('bf_2016_05', engine)\n",
    "\n",
    "bf_2016_06_df = drill_down(ba_2016,'06')\n",
    "bf_2016_06_df.to_sql('bf_2016_06', engine)\n",
    "\n",
    "bf_2016_08_df = drill_down(ba_2016,'08')\n",
    "bf_2016_08_df.to_sql('bf_2016_08', engine)\n",
    "\n",
    "bf_2016_09_df = drill_down(ba_2016,'09')\n",
    "bf_2016_09_df.to_sql('bf_2016_09', engine)\n",
    "\n",
    "bf_2016_10_df = drill_down(ba_2016,'10')\n",
    "bf_2016_10_df.to_sql('bf_2016_10', engine)\n",
    "\n",
    "bf_2016_11_df = drill_down(ba_2016,'11')\n",
    "bf_2016_11_df.to_sql('bf_2016_11', engine)\n",
    "\n",
    "bf_2016_12_df = drill_down(ba_2016,'12')\n",
    "bf_2016_12_df.to_sql('bf_2016_12', engine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_2015_01_df = drill_down(ba_2015,'01')\n",
    "bf_2015_01_df.to_sql('bf_2015_01', engine)\n",
    "\n",
    "bf_2015_02_df = drill_down(ba_2015,'02')\n",
    "bf_2015_02_df.to_sql('bf_2015_02', engine)\n",
    "\n",
    "bf_2015_03_df = drill_down(ba_2015,'03')\n",
    "bf_2015_03_df.to_sql('bf_2015_03', engine)\n",
    "\n",
    "bf_2015_04_df = drill_down(ba_2015,'04')\n",
    "bf_2015_04_df.to_sql('bf_2015_04', engine)\n",
    "\n",
    "bf_2015_05_df = drill_down(ba_2015,'05')\n",
    "bf_2015_05_df.to_sql('bf_2015_05', engine)\n",
    "\n",
    "bf_2015_06_df = drill_down(ba_2015,'06')\n",
    "bf_2015_06_df.to_sql('bf_2015_06', engine)\n",
    "\n",
    "bf_2015_08_df = drill_down(ba_2015,'08')\n",
    "bf_2015_08_df.to_sql('bf_2015_08', engine)\n",
    "\n",
    "bf_2015_09_df = drill_down(ba_2015,'09')\n",
    "bf_2015_09_df.to_sql('bf_2015_09', engine)\n",
    "\n",
    "bf_2015_10_df = drill_down(ba_2015,'10')\n",
    "bf_2015_10_df.to_sql('bf_2015_10', engine)\n",
    "\n",
    "bf_2015_11_df = drill_down(ba_2015,'11')\n",
    "bf_2015_11_df.to_sql('bf_2015_11', engine)\n",
    "\n",
    "bf_2015_12_df = drill_down(ba_2015,'12')\n",
    "bf_2015_12_df.to_sql('bf_2015_12', engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_2014_01_df = drill_down(ba_2014,'01')\n",
    "bf_2014_01_df.to_sql('bf_2014_01', engine)\n",
    "\n",
    "bf_2014_02_df = drill_down(ba_2014,'02')\n",
    "bf_2014_02_df.to_sql('bf_2014_02', engine)\n",
    "\n",
    "bf_2014_03_df = drill_down(ba_2014,'03')\n",
    "bf_2014_03_df.to_sql('bf_2014_03', engine)\n",
    "\n",
    "bf_2014_04_df = drill_down(ba_2014,'04')\n",
    "bf_2014_04_df.to_sql('bf_2014_04', engine)\n",
    "\n",
    "bf_2014_05_df = drill_down(ba_2014,'05')\n",
    "bf_2014_05_df.to_sql('bf_2014_05', engine)\n",
    "\n",
    "bf_2014_06_df = drill_down(ba_2014,'06')\n",
    "bf_2014_06_df.to_sql('bf_2014_06', engine)\n",
    "\n",
    "bf_2014_08_df = drill_down(ba_2014,'08')\n",
    "bf_2014_08_df.to_sql('bf_2014_08', engine)\n",
    "\n",
    "bf_2014_09_df = drill_down(ba_2014,'09')\n",
    "bf_2014_09_df.to_sql('bf_2014_09', engine)\n",
    "\n",
    "bf_2014_10_df = drill_down(ba_2014,'10')\n",
    "bf_2014_10_df.to_sql('bf_2014_10', engine)\n",
    "\n",
    "bf_2014_11_df = drill_down(ba_2014,'11')\n",
    "bf_2014_11_df.to_sql('bf_2014_11', engine)\n",
    "\n",
    "bf_2014_12_df = drill_down(ba_2014,'12')\n",
    "bf_2014_12_df.to_sql('bf_2014_12', engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_2013_01_df = drill_down(ba_2013,'01')\n",
    "bf_2013_01_df.to_sql('bf_2013_01', engine)\n",
    "\n",
    "bf_2013_02_df = drill_down(ba_2013,'02')\n",
    "bf_2013_02_df.to_sql('bf_2013_02', engine)\n",
    "\n",
    "bf_2013_03_df = drill_down(ba_2013,'03')\n",
    "bf_2013_03_df.to_sql('bf_2013_03', engine)\n",
    "\n",
    "bf_2013_04_df = drill_down(ba_2013,'04')\n",
    "bf_2013_04_df.to_sql('bf_2013_04', engine)\n",
    "\n",
    "bf_2013_05_df = drill_down(ba_2013,'05')\n",
    "bf_2013_05_df.to_sql('bf_2013_05', engine)\n",
    "\n",
    "bf_2013_06_df = drill_down(ba_2013,'06')\n",
    "bf_2013_06_df.to_sql('bf_2013_06', engine)\n",
    "\n",
    "bf_2013_08_df = drill_down(ba_2013,'08')\n",
    "bf_2013_08_df.to_sql('bf_2013_08', engine)\n",
    "\n",
    "bf_2013_09_df = drill_down(ba_2013,'09')\n",
    "bf_2013_09_df.to_sql('bf_2013_09', engine)\n",
    "\n",
    "bf_2013_10_df = drill_down(ba_2013,'10')\n",
    "bf_2013_10_df.to_sql('bf_2013_10', engine)\n",
    "\n",
    "bf_2013_11_df = drill_down(ba_2013,'11')\n",
    "bf_2013_11_df.to_sql('bf_2013_11', engine)\n",
    "\n",
    "bf_2013_12_df = drill_down(ba_2013,'12')\n",
    "bf_2013_12_df.to_sql('bf_2013_12', engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_2012_01_df = drill_down(ba_2012,'01')\n",
    "bf_2012_01_df.to_sql('bf_2012_01', engine)\n",
    "\n",
    "bf_2012_02_df = drill_down(ba_2012,'02')\n",
    "bf_2012_02_df.to_sql('bf_2012_02', engine)\n",
    "\n",
    "bf_2012_03_df = drill_down(ba_2012,'03')\n",
    "bf_2012_03_df.to_sql('bf_2012_03', engine)\n",
    "\n",
    "bf_2012_04_df = drill_down(ba_2012,'04')\n",
    "bf_2012_04_df.to_sql('bf_2012_04', engine)\n",
    "\n",
    "bf_2012_05_df = drill_down(ba_2012,'05')\n",
    "bf_2012_05_df.to_sql('bf_2012_05', engine)\n",
    "\n",
    "bf_2012_06_df = drill_down(ba_2012,'06')\n",
    "bf_2012_06_df.to_sql('bf_2012_06', engine)\n",
    "\n",
    "bf_2012_08_df = drill_down(ba_2012,'08')\n",
    "bf_2012_08_df.to_sql('bf_2012_08', engine)\n",
    "\n",
    "bf_2012_09_df = drill_down(ba_2012,'09')\n",
    "bf_2012_09_df.to_sql('bf_2012_09', engine)\n",
    "\n",
    "bf_2012_10_df = drill_down(ba_2012,'10')\n",
    "bf_2012_10_df.to_sql('bf_2012_10', engine)\n",
    "\n",
    "bf_2012_11_df = drill_down(ba_2012,'11')\n",
    "bf_2012_11_df.to_sql('bf_2012_11', engine)\n",
    "\n",
    "bf_2012_12_df = drill_down(ba_2012,'12')\n",
    "bf_2012_12_df.to_sql('bf_2012_12', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ba_sum = ba2016_01.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ba_sum/3060\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
